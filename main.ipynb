{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Parser\n",
    "Parser functions used to parse requests along with their properties from the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import string\n",
    "import urllib.parse as urlparse\n",
    "from setuptools import Feature\n",
    "\n",
    "HTTP_METHODS = {\n",
    "    \"GET\": \"GET(.|\\n)+?(?=GET|POST|\\Z)\",\n",
    "    \"POST\": \"POST(.|\\n)+?(?=GET|POST|\\Z)\"\n",
    "}\n",
    "\n",
    "URL_REGEX = \"http.+?(?= )\"\n",
    "BODY_REGEX = \"(?<=\\n\\n).+(?=\\n\\n)\"\n",
    "\n",
    "\n",
    "\n",
    "def parse(path, request_reg: string):\n",
    "    with open(path) as file:\n",
    "        data = file.read()\n",
    "\n",
    "        requests = []\n",
    "        [requests.append(request.group(0)) for request in re.finditer(request_reg, data, re.MULTILINE)]\n",
    "\n",
    "        return requests\n",
    "\n",
    "def parseParamsFromUrl(request):\n",
    "    url = parseUrl(request)\n",
    "    return urlparse.parse_qs(urlparse.urlparse(url).query)\n",
    "\n",
    "def parseUrl(request):\n",
    "    return re.search(URL_REGEX, request).group(0)\n",
    "\n",
    "def parseParamsFromBody(request):\n",
    "    params = {}\n",
    "    body = re.search(BODY_REGEX, request)\n",
    "\n",
    "    if body is not None:\n",
    "        body = body.group(0)\n",
    "\n",
    "        params = urlparse.parse_qs(body)\n",
    "\n",
    "    return params\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Features\n",
    "Calculator classes are used to extract feature from the given string. \n",
    "With respect to scalability, every feature has its own class that takes care of calculation. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "import string\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "\n",
    "class FeatureCalculator(metaclass=ABCMeta):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform(self, s: string, request_type=False):\n",
    "        pass\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "class LengthFeatureCalculator(FeatureCalculator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, s: string, request_type=False):\n",
    "        return len(s)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "class LettersFeatureCalculator(FeatureCalculator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, s: string, request_type=False):\n",
    "        return sum(c.isalpha() for c in s)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "class NonAlphaFeatureCalculator(FeatureCalculator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, s: string, request_type=False):\n",
    "        return sum((not c.isalpha()) for c in s)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "class PathLengthFeatureCalculator(FeatureCalculator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, s: string, request_type=False):\n",
    "\n",
    "        if not request_type:\n",
    "            return 0\n",
    "\n",
    "        return len(parseUrl(s))\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "class PathNonAlphaFeatureCalculator(FeatureCalculator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, s: string, request_type=False):\n",
    "\n",
    "        if not request_type:\n",
    "            return 0\n",
    "\n",
    "        return sum((not c.isalpha()) for c in parseUrl(s))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "\n",
    "class EntropyFeatureCalculator(FeatureCalculator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, s: string, request_type=False):\n",
    "        return (-1) * sum(\n",
    "            i / len(s) * math.log2(i / len(s))\n",
    "            for i in collections.Counter(s).values())\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "class DigitsFeatureCalculator(FeatureCalculator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, s: string, request_type=False):\n",
    "        return sum(c.isdigit() for c in s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "class ArgumentsLengthFeatureCalculator(FeatureCalculator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, s: string, request_type=False):\n",
    "\n",
    "        if not request_type:\n",
    "            return 0\n",
    "\n",
    "        urlParams = parseParamsFromUrl(s)\n",
    "        bodyParams = parseParamsFromBody(s)\n",
    "\n",
    "        params = {**urlParams, **bodyParams}\n",
    "\n",
    "        length = 0\n",
    "\n",
    "        for param in params.items():\n",
    "            length = length + len(param[0])\n",
    "\n",
    "        return length\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "class ArgumentsNumberFeatureCalculator(FeatureCalculator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, s: string, request_type=False):\n",
    "\n",
    "        if not request_type:\n",
    "            return 0\n",
    "\n",
    "        urlParams = parseParamsFromUrl(s)\n",
    "        bodyParams = parseParamsFromBody(s)\n",
    "\n",
    "        params = {**urlParams, **bodyParams}\n",
    "\n",
    "        return len(params)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classifier\n",
    "Classifier class using One-Class SVM to train and classify on the given datasets\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "class AnomalyClassifier():\n",
    "    def __init__(self, training_data_path):\n",
    "        self.training_data_path = training_data_path\n",
    "        self.param_features_allowed = True\n",
    "        self.bodyparams_features_allowed = True\n",
    "\n",
    "        self.feature_calculators = [\n",
    "            LengthFeatureCalculator(),\n",
    "            DigitsFeatureCalculator(),\n",
    "            LettersFeatureCalculator(),\n",
    "            NonAlphaFeatureCalculator(),\n",
    "            EntropyFeatureCalculator(),\n",
    "            ArgumentsLengthFeatureCalculator(),\n",
    "            ArgumentsNumberFeatureCalculator(),\n",
    "            PathLengthFeatureCalculator(),\n",
    "            PathNonAlphaFeatureCalculator()\n",
    "        ]\n",
    "\n",
    "        self.classifiers = {}\n",
    "\n",
    "    def train_all_methods(self, nu=0.1, kernel=\"rbf\", gamma=0.1):\n",
    "        for method, regex in HTTP_METHODS.items():\n",
    "            self.train(method, regex, nu=nu, kernel=kernel, gamma=gamma)\n",
    "\n",
    "    def train_get_method(self):\n",
    "        self.train(HTTP_METHODS[\"GET\"].index(), HTTP_METHODS[\"GET\"])\n",
    "\n",
    "    def train_post_method(self):\n",
    "        self.train(HTTP_METHODS[\"POST\"].index(), HTTP_METHODS[\"POST\"])\n",
    "\n",
    "    def train(self, method: string, regex: string, nu=0.1, kernel=\"rbf\", gamma=0.1):\n",
    "        requests = parse(self.training_data_path, regex)\n",
    "\n",
    "        X = []\n",
    "\n",
    "        print(\"training for \" + method + \" method\")\n",
    "\n",
    "        for request in requests:\n",
    "            X.append(self.calculate_features(request, param_features_allowed=self.param_features_allowed, bodyparam_features_allowed=self.bodyparams_features_allowed))\n",
    "            if len(X) % 5000 == 0:\n",
    "                print(str(len(X)) + \" examples processed\")\n",
    "\n",
    "        X = self.balance_X(X)\n",
    "\n",
    "        classif = OneClassSVM(nu=nu, kernel=kernel, gamma=gamma, cache_size=500)\n",
    "\n",
    "        print(\"fitting the classifier\")\n",
    "        classif.fit(X)\n",
    "        self.classifiers[method] = classif\n",
    "\n",
    "    def classify(self, path):\n",
    "\n",
    "        classification = []\n",
    "\n",
    "        for method, regex in HTTP_METHODS.items():\n",
    "            requests = parse(path, regex)\n",
    "\n",
    "            print(\"test evaluation with \" + method + \" method for \" + str(len(requests)) + \" requests\")\n",
    "\n",
    "            X = []\n",
    "\n",
    "            for request in requests:\n",
    "                X.append(self.calculate_features(request, param_features_allowed=self.param_features_allowed, bodyparam_features_allowed=self.bodyparams_features_allowed))\n",
    "\n",
    "            X = self.balance_X(X)\n",
    "\n",
    "            classification.append(self.classifiers[method].predict(X))\n",
    "\n",
    "        Y = np.concatenate(classification)\n",
    "\n",
    "        return Y\n",
    "\n",
    "    def calculate_features(self, request: string, param_features_allowed: bool, bodyparam_features_allowed: bool):\n",
    "        features = []\n",
    "        for calculator in self.feature_calculators:\n",
    "            features.append(calculator.transform(request, True))\n",
    "\n",
    "        if param_features_allowed:\n",
    "            params = parseParamsFromUrl(request)\n",
    "            for param in params.items():\n",
    "                for calculator in self.feature_calculators:\n",
    "                    features.append(calculator.transform(param[0]))\n",
    "\n",
    "        if bodyparam_features_allowed:\n",
    "            params = parseParamsFromBody(request)\n",
    "            for param in params.items():\n",
    "                for calculator in self.feature_calculators:\n",
    "                    features.append(calculator.transform(param[0]))\n",
    "\n",
    "        return features\n",
    "\n",
    "    def balance_X(self, X):\n",
    "        X_processed = np.zeros([len(X), len(max(X, key=lambda x: len(x)))])\n",
    "        for i, j in enumerate(X):\n",
    "            X_processed[i][0:len(j)] = j\n",
    "\n",
    "        return X_processed\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_DATA_PATH = \"data/normalTrafficTraining.txt\"\n",
    "TEST_DATA_NORMAL_PATH = \"data/normalTrafficTest.txt\"\n",
    "TEST_DATA_ANOMALY_PATH = \"data/anomalousTrafficTest.txt\"\n",
    "ANOMALIES_LABEL = -1\n",
    "NORMAL_LABEL = 1\n",
    "\n",
    "class Evaluator():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def evaluate_performance(self, nu, kernel, gamma):\n",
    "        print(\"[RUNNING EVALUATION FOR {nu: \" + str(nu) + \", kernel: \" + str(kernel) + \", gamma: \" + str(gamma) + \"}]\")\n",
    "        print(\"[Training phase]\")\n",
    "        classifier = AnomalyClassifier(TRAIN_DATA_PATH)\n",
    "        classifier.train_all_methods(nu=nu, kernel=kernel, gamma=gamma)\n",
    "        print(\"- classifier trained\")\n",
    "        print(\"-----------------\")\n",
    "        \n",
    "        print(\"[Testing phase for ANOMALIES dataset]\")\n",
    "        Y = classifier.classify(TEST_DATA_ANOMALY_PATH)\n",
    "        \n",
    "        anomalies = Y[Y == ANOMALIES_LABEL].size\n",
    "        normal = Y[Y == NORMAL_LABEL].size\n",
    "        \n",
    "        print(\"- results: \")\n",
    "        print(\"  - anomalies ratio: \" + str(anomalies) + \" / \" + str(len(Y)))\n",
    "        print(\"  - anomalies percentage cover: \" + str((anomalies / len(Y)) * 100) + \"%\")\n",
    "        print(\"  - error rate: \" + str((normal / len(Y)) * 100) + \"%\")\n",
    "        print(\"-----------------\")\n",
    "        \n",
    "        print(\"[Testing phase for NORMAL dataset]\")\n",
    "        Y = classifier.classify(TEST_DATA_NORMAL_PATH)\n",
    "        \n",
    "        anomalies = Y[Y == ANOMALIES_LABEL].size\n",
    "        normal = Y[Y == NORMAL_LABEL].size\n",
    "        \n",
    "        print(\"- results: \")\n",
    "        print(\"  - normal ratio: \" + str(normal) + \" / \" + str(len(Y)))\n",
    "        print(\"  - normal percentage cover: \" + str((normal / len(Y)) * 100) + \"%\")\n",
    "        print(\"  - error rate: \" + str((anomalies / len(Y)) * 100) + \"%\")\n",
    "        print(\"-----------------\")\n",
    "        print(\"-----------------\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run the evaluation on different configuration parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[RUNNING EVALUATION FOR {nu: 0.1, kernel: rbf, gamma: 0.1}]\n[Training phase]\n",
      "training for GET method\n",
      "5000 examples processed\n",
      "10000 examples processed\n",
      "15000 examples processed\n",
      "20000 examples processed\n",
      "25000 examples processed\n",
      "training for POST method\n",
      "5000 examples processed\n",
      "- classifier trained\n-----------------\n[Testing phase for ANOMALIES dataset]\n",
      "test evaluation with GET method for 15088 requests\n",
      "test evaluation with POST method for 9580 requests\n",
      "- results: \n  - anomalies ratio: 23299 / 24668\n  - anomalies percentage cover: 94.45029998378466%\n  - error rate: 5.54970001621534%\n-----------------\n[Testing phase for NORMAL dataset]\n",
      "test evaluation with GET method for 28000 requests\n",
      "test evaluation with POST method for 8000 requests\n",
      "- results: \n  - normal ratio: 29777 / 36000\n  - normal percentage cover: 82.71388888888889%\n  - error rate: 17.28611111111111%\n-----------------\n-----------------\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# svm values\n",
    "NU = [0.1] # [0.1, 0.01, 0.001, 0.0001]\n",
    "GAMMA = [0.1] # [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "for nu in NU:\n",
    "    for gamma in GAMMA:\n",
    "        evaluator.evaluate_performance(nu, \"rbf\", gamma)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}