{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Parser\n",
    "Parser functions used to parse requests along with their properties from the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import string\n",
    "import urllib.parse as urlparse\n",
    "from setuptools import Feature\n",
    "\n",
    "HTTP_METHODS = {\n",
    "    \"GET\": \"GET(.|\\n)+?(?=GET|POST|\\Z)\",\n",
    "    \"POST\": \"POST(.|\\n)+?(?=GET|POST|\\Z)\"\n",
    "}\n",
    "\n",
    "URL_REGEX = \"http.+?(?= )\"\n",
    "BODY_REGEX = \"(?<=\\n\\n).+(?=\\n\\n)\"\n",
    "\n",
    "\n",
    "\n",
    "def parse(path, request_reg: string):\n",
    "    with open(path) as file:\n",
    "        data = file.read()\n",
    "\n",
    "        requests = []\n",
    "        [requests.append(request.group(0)) for request in re.finditer(request_reg, data, re.MULTILINE)]\n",
    "\n",
    "        return requests\n",
    "\n",
    "def parseParamsFromUrl(request):\n",
    "    url = parseUrl(request)\n",
    "    return urlparse.parse_qs(urlparse.urlparse(url).query)\n",
    "\n",
    "def parseUrl(request):\n",
    "    return re.search(URL_REGEX, request).group(0)\n",
    "\n",
    "def parseParamsFromBody(request):\n",
    "    params = {}\n",
    "    body = re.search(BODY_REGEX, request)\n",
    "\n",
    "    if body is not None:\n",
    "        body = body.group(0)\n",
    "\n",
    "        params = urlparse.parse_qs(body)\n",
    "\n",
    "    return params\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Features\n",
    "Calculator classes are used to extract feature from the given string. \n",
    "With respect to scalability, every feature has its own class that takes care of calculation. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import string\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "\n",
    "class FeatureCalculator(metaclass=ABCMeta):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform(self, s: string, request_type=False):\n",
    "        pass\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class LengthFeatureCalculator(FeatureCalculator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, s: string, request_type=False):\n",
    "        return len(s)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class LettersFeatureCalculator(FeatureCalculator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, s: string, request_type=False):\n",
    "        return sum(c.isalpha() for c in s)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class NonAlphaFeatureCalculator(FeatureCalculator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, s: string, request_type=False):\n",
    "        return sum((not c.isalpha()) for c in s)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class PathLengthFeatureCalculator(FeatureCalculator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, s: string, request_type=False):\n",
    "\n",
    "        if not request_type:\n",
    "            return 0\n",
    "\n",
    "        return len(parseUrl(s))\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class PathNonAlphaFeatureCalculator(FeatureCalculator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, s: string, request_type=False):\n",
    "\n",
    "        if not request_type:\n",
    "            return 0\n",
    "\n",
    "        return sum((not c.isalpha()) for c in parseUrl(s))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "\n",
    "class EntropyFeatureCalculator(FeatureCalculator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, s: string, request_type=False):\n",
    "        return (-1) * sum(\n",
    "            i / len(s) * math.log2(i / len(s))\n",
    "            for i in collections.Counter(s).values())\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class DigitsFeatureCalculator(FeatureCalculator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, s: string, request_type=False):\n",
    "        return sum(c.isdigit() for c in s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class ArgumentsLengthFeatureCalculator(FeatureCalculator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, s: string, request_type=False):\n",
    "\n",
    "        if not request_type:\n",
    "            return 0\n",
    "\n",
    "        urlParams = parseParamsFromUrl(s)\n",
    "        bodyParams = parseParamsFromBody(s)\n",
    "\n",
    "        params = {**urlParams, **bodyParams}\n",
    "\n",
    "        length = 0\n",
    "\n",
    "        for param in params.items():\n",
    "            length = length + len(param[0])\n",
    "\n",
    "        return length\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class ArgumentsNumberFeatureCalculator(FeatureCalculator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, s: string, request_type=False):\n",
    "\n",
    "        if not request_type:\n",
    "            return 0\n",
    "\n",
    "        urlParams = parseParamsFromUrl(s)\n",
    "        bodyParams = parseParamsFromBody(s)\n",
    "\n",
    "        params = {**urlParams, **bodyParams}\n",
    "\n",
    "        return len(params)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classifier\n",
    "Classifier class using One-Class SVM to train and classify on the given datasets\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-73f7f10beef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mAnomalyClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_data_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_data_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-73f7f10beef8>\u001b[0m in \u001b[0;36mAnomalyClassifier\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTTP_METHODS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHTTP_METHODS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rbf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mrequests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'string' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'string' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "\n",
    "class AnomalyClassifier():\n",
    "    def __init__(self, training_data_path):\n",
    "        self.training_data_path = training_data_path\n",
    "        self.param_features_allowed = True\n",
    "        self.bodyparams_features_allowed = True\n",
    "\n",
    "        self.feature_calculators = [\n",
    "            LengthFeatureCalculator(),\n",
    "            DigitsFeatureCalculator(),\n",
    "            LettersFeatureCalculator(),\n",
    "            NonAlphaFeatureCalculator(),\n",
    "            EntropyFeatureCalculator(),\n",
    "            ArgumentsLengthFeatureCalculator(),\n",
    "            ArgumentsNumberFeatureCalculator(),\n",
    "            PathLengthFeatureCalculator(),\n",
    "            PathNonAlphaFeatureCalculator()\n",
    "        ]\n",
    "\n",
    "        self.classifiers = {}\n",
    "\n",
    "    def train_all_methods(self, nu=0.1, kernel=\"rbf\", gamma=0.1):\n",
    "        for method, regex in HTTP_METHODS.items():\n",
    "            self.train(method, regex)\n",
    "\n",
    "    def train_get_method(self):\n",
    "        self.train(HTTP_METHODS[\"GET\"].index(), HTTP_METHODS[\"GET\"])\n",
    "\n",
    "    def train_post_method(self):\n",
    "        self.train(HTTP_METHODS[\"POST\"].index(), HTTP_METHODS[\"POST\"])\n",
    "\n",
    "    def train(self, method: string, regex: string, nu=0.1, kernel=\"rbf\", gamma=0.1):\n",
    "        requests = parse(self.training_data_path, regex)\n",
    "\n",
    "        X = []\n",
    "\n",
    "        # print(\"training for \" + method + \" method\")\n",
    "\n",
    "        for request in requests:\n",
    "            X.append(self.calculate_features(request, param_features_allowed=self.param_features_allowed, bodyparam_features_allowed=self.bodyparams_features_allowed))\n",
    "            # if len(X) % 1000 == 0:\n",
    "            #     print(str(len(X)) + \" examples processed\")\n",
    "\n",
    "        X = self.balance_X(X)\n",
    "\n",
    "        classif = OneClassSVM(nu=nu, kernel=kernel, gamma=gamma, cache_size=500)\n",
    "\n",
    "        classif.fit(X)\n",
    "        self.classifiers[method] = classif\n",
    "\n",
    "    def classify(self, path):\n",
    "\n",
    "        classification = []\n",
    "\n",
    "        for method, regex in HTTP_METHODS.items():\n",
    "            requests = parse(path, regex)\n",
    "\n",
    "            # print(\"test evaluation with \" + method + \" method for \" + str(len(requests)) + \" requests\")\n",
    "\n",
    "            X = []\n",
    "\n",
    "            for request in requests:\n",
    "                X.append(self.calculate_features(request, param_features_allowed=self.param_features_allowed, bodyparam_features_allowed=self.bodyparams_features_allowed))\n",
    "\n",
    "            X = self.balance_X(X)\n",
    "\n",
    "            classification.append(self.classifiers[method].predict(X))\n",
    "\n",
    "        Y = np.concatenate(classification)\n",
    "\n",
    "        return Y\n",
    "\n",
    "    def calculate_features(self, request: string, param_features_allowed: bool, bodyparam_features_allowed: bool):\n",
    "        features = []\n",
    "        for calculator in self.feature_calculators:\n",
    "            features.append(calculator.transform(request, True))\n",
    "\n",
    "        if param_features_allowed:\n",
    "            params = parseParamsFromUrl(request)\n",
    "            for param in params.items():\n",
    "                for calculator in self.feature_calculators:\n",
    "                    features.append(calculator.transform(param[0]))\n",
    "\n",
    "        if bodyparam_features_allowed:\n",
    "            params = parseParamsFromBody(request)\n",
    "            for param in params.items():\n",
    "                for calculator in self.feature_calculators:\n",
    "                    features.append(calculator.transform(param[0]))\n",
    "\n",
    "        return features\n",
    "\n",
    "    def balance_X(self, X):\n",
    "        X_processed = np.zeros([len(X), len(max(X, key=lambda x: len(x)))])\n",
    "        for i, j in enumerate(X):\n",
    "            X_processed[i][0:len(j)] = j\n",
    "\n",
    "        return X_processed\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_DATA_PATH = \"data/normalTrafficTraining.txt\"\n",
    "TEST_DATA_NORMAL_PATH = \"data/normalTrafficTest.txt\"\n",
    "TEST_DATA_ANOMALY_PATH = \"data/anomalousTrafficTest.txt\"\n",
    "ANOMALIES_LABEL = -1\n",
    "NORMAL_LABEL = 1\n",
    "\n",
    "class Evaluator():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def evaluate_performance(self, nu, kernel, gamma):\n",
    "        print(\"[RUNNING EVALUATION FOR {nu: \" + str(nu) + \", kernel: \" + str(kernel) + \", gamma: \" + str(gamma) + \"}]\")\n",
    "        print(\"[Training phase]\")\n",
    "        classifier = AnomalyClassifier(TRAIN_DATA_PATH)\n",
    "        classifier.train_all_methods()\n",
    "        print(\"- classifier trained\")\n",
    "        print(\"-----------------\")\n",
    "        \n",
    "        print(\"[Testing phase for ANOMALIES dataset]\")\n",
    "        Y = classifier.classify(TEST_DATA_ANOMALY_PATH)\n",
    "        \n",
    "        anomalies = Y[Y == ANOMALIES_LABEL].size\n",
    "        normal = Y[Y == NORMAL_LABEL].size\n",
    "        \n",
    "        print(\"- results: \")\n",
    "        print(\"- anomalies ratio: \" + str(anomalies) + \" / \" + str(len(Y)))\n",
    "        print(\"- anomalies percentage cover: \" + str((anomalies / len(Y)) * 100) + \"%\")\n",
    "        print(\"- error rate: \" + str((normal / len(Y)) * 100) + \"%\")\n",
    "        print(\"-----------------\")\n",
    "        \n",
    "        print(\"[Testing phase for NORMAL dataset]\")\n",
    "        Y = classifier.classify(TEST_DATA_NORMAL_PATH)\n",
    "        \n",
    "        anomalies = Y[Y == ANOMALIES_LABEL].size\n",
    "        normal = Y[Y == NORMAL_LABEL].size\n",
    "        \n",
    "        print(\"results: \")\n",
    "        print(\"- normal ratio: \" + str(normal) + \" / \" + str(len(Y)))\n",
    "        print(\"- normal percentage cover: \" + str((normal / len(Y)) * 100) + \"%\")\n",
    "        print(\"- error rate: \" + str((anomalies / len(Y)) * 100) + \"%\")\n",
    "        print(\"-----------------\")\n",
    "        print(\"-----------------\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run the evaluation on different configuration parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[RUNNING EVALUATION FOR {nu: 0.1, kernel: rbf, gamma0.1}]\n[Training phase]\n",
      "training for GET method\n",
      "1000 examples processed\n",
      "2000 examples processed\n",
      "3000 examples processed\n",
      "4000 examples processed\n",
      "5000 examples processed\n",
      "6000 examples processed\n",
      "7000 examples processed\n",
      "8000 examples processed\n",
      "9000 examples processed\n",
      "10000 examples processed\n",
      "11000 examples processed\n",
      "12000 examples processed\n",
      "13000 examples processed\n",
      "14000 examples processed\n",
      "15000 examples processed\n",
      "16000 examples processed\n",
      "17000 examples processed\n",
      "18000 examples processed\n",
      "19000 examples processed\n",
      "20000 examples processed\n",
      "21000 examples processed\n",
      "22000 examples processed\n",
      "23000 examples processed\n",
      "24000 examples processed\n",
      "25000 examples processed\n",
      "26000 examples processed\n",
      "27000 examples processed\n",
      "28000 examples processed\n",
      "training for POST method\n",
      "1000 examples processed\n",
      "2000 examples processed\n",
      "3000 examples processed\n",
      "4000 examples processed\n",
      "5000 examples processed\n",
      "6000 examples processed\n",
      "7000 examples processed\n",
      "8000 examples processed\n",
      "- classifier trained\n-----------------\n[Testing phase for ANOMALIES dataset]\n",
      "test evaluation with GET method for 15088 requests\n",
      "test evaluation with POST method for 9580 requests\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8c8116f0fdf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mNU\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rbf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-57f81d0e2acb>\u001b[0m in \u001b[0;36mevaluate_performance\u001b[0;34m(self, nu, kernel, gamma)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[Testing phase for ANOMALIES dataset]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_DATA_ANOMALY_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0manomalies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mANOMALIES_LABEL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-f15333159a45>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbalance_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/School/CVUT-FEL/diploma/assignments/blindspot/http_anomaly_detection/env/lib/python3.7/site-packages/sklearn/svm/classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \"\"\"\n\u001b[0;32m-> 1240\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/School/CVUT-FEL/diploma/assignments/blindspot/http_anomaly_detection/env/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/School/CVUT-FEL/diploma/assignments/blindspot/http_anomaly_detection/env/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             cache_size=self.cache_size)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "# svm values\n",
    "NU = [0.1, 0.01, 0.001, 0.0001]\n",
    "GAMMA = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "for nu in NU:\n",
    "    for gamma in GAMMA:\n",
    "        evaluator.evaluate_performance(nu, \"rbf\", gamma)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}